# WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image

**WSI-LLaVA** is a multimodal large language model designed for Whole Slide Image (WSI) analysis, bridging the gap between gigapixel WSIs and textual descriptions. It introduces innovative methods and benchmarks for advancing pathology-focused AI research.

---

## ðŸ“‹ Key Contributions

- **WSI-Bench**: The first large-scale, morphology-aware benchmark for gigapixel WSI understanding and evaluation. It includes:
  - **180k VQA pairs** from **9,850 WSIs** across **30 cancer types**.
  - Emphasis on morphological observations to enhance WSI-level multimodal large language models (MLLMs).
  
- **WSI-LLaVA Framework**:
  - A novel three-stage training approach:
    1. **WSI-Text Alignment**
    2. **Feature Space Alignment**
    3. **Task-Specific Instruction Tuning**

- **WSI-Specific Evaluation Metrics**:
  - **WSI-Precision**: Evaluates the accuracy of model responses against the ground truth.
  - **WSI-Relevance**: Measures how well the model's responses align with the ground truth.

---

## ðŸ—ï¸ Architecture

WSI-LLaVA consists of three core components:
1. **WSI Encoder**: Processes gigapixel WSIs for feature extraction.
2. **Projection Layer**: Aligns WSI features with textual embeddings.
3. **Large Language Model**: Generates context-aware and clinically relevant textual responses.

The training strategy incorporates three key stages for optimal performance on gigapixel WSIs.

![WSI-LLaVA Architecture](image/architecture_new4.png)

---

## ðŸ“Š WSI-Bench

In clinical practice, morphological features such as tissue and cellular structural abnormalities play a critical role in diagnosis. Existing models often overlook these crucial details. To address this, we propose **WSI-Bench**:

- **Scope**: 180k VQA pairs from 9,850 WSIs, spanning 30 cancer types and sourced from 8,368 patients.
- **Tasks**: 11 pathology-focused VQA tasks designed to evaluate three major pathological capabilities.

![WSI-Bench Construction](image/build_dataset_new.png)

---

## ðŸ“‚ Open Resources

We are committed to transparency and open science. Currently, the following resources are available:

- **[Dataset (Partial)](./dataset/)**: A subset of VQA pairs and WSI data for select cancer types.
- **Pre-trained Weights**: *Coming Soon*.
- **Training Set**: *Coming Soon*.

> **Note:** Additional dataset partitions and fine-tuned weights will be released in future updates.

---

## ðŸ“· Additional Visuals

### **WSI-LLaVA Key Contributions**
![Key Contributions](image/metric.png)

### **WSI Bench Overview**
![WSI Bench Overview](image/wsi-beach.png)

---

This README introduces the **WSI-LLaVA** project, highlights its key contributions, describes the architecture, and provides access to resources such as datasets. Updates for weights and training data will follow in subsequent releases. Let us know if you have any questions or feedback!
# WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image

**WSI-LLaVA** is a multimodal large language model designed for Whole Slide Image (WSI) analysis, bridging the gap between gigapixel WSIs and textual descriptions. It introduces innovative methods and benchmarks for advancing pathology-focused AI research.


## 🏗️ Architecture

WSI-LLaVA consists of three core components:
1. **WSI Encoder**: Processes gigapixel WSIs for feature extraction.
2. **Projection Layer**: Aligns WSI features with textual embeddings.
3. **Large Language Model**: Generates context-aware and clinically relevant textual responses.

The training strategy incorporates three key stages for optimal performance on gigapixel WSIs.

![WSI-LLaVA Architecture](image/architecture_new4.png)

---

## 📊 WSI-Bench

In clinical practice, morphological features such as tissue and cellular structural abnormalities play a critical role in diagnosis. Existing models often overlook these crucial details. To address this, we propose **WSI-Bench**:

- **Scope**: 180k VQA pairs from 9,850 WSIs, spanning 30 cancer types and sourced from 8,368 patients.
- **Tasks**: 11 pathology-focused VQA tasks designed to evaluate three major pathological capabilities.

![WSI Bench Overview](image/wsi-beach.png)

---

## 📂 Open Resources

We are committed to transparency and open science. Currently, the following resources are available:

- **[Dataset (Partial)](./dataset/)**: A subset of VQA pairs and WSI data for select cancer types.
- **Pre-trained Weights**: *Coming Soon*.
- **Training Set**: *Coming Soon*.

> **Note:** Additional dataset partitions and fine-tuned weights will be released in future updates.

---

## 📷 Additional Visuals

### **WSI-LLaVA Key Contributions**
![Key Contributions](image/metric.png)

---

This README introduces the **WSI-LLaVA** project, highlights its key contributions, describes the architecture, and provides access to resources such as datasets. Updates for weights and training data will follow in subsequent releases. Let us know if you have any questions or feedback!